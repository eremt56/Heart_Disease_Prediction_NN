{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1649333178.py, line 73)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 73\u001b[0;36m\u001b[0m\n\u001b[0;31m    temp1 = input.dot((weight2.dot(((third2 * third1).dot(output)).dot(A2.dot((A2*-1) += 1)))).dot(A1.dot((A1*-1) += 1)))\u001b[0m\n\u001b[0m                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "# Algorithms:\n",
    "class Algorithms:\n",
    "\n",
    "    def _init_():\n",
    "        pass\n",
    "\n",
    "\n",
    "    #initializing weights and biases:\n",
    "    def init():\n",
    "        '''Initialize all weights and biases:\n",
    "        2 Hidden Layer\n",
    "        1 Output Layer'''\n",
    "        \n",
    "        weight1 = (np.random.rand(11, 5) * 2) - 1\n",
    "        bias1 = (np.random.randn(5,1)*2)-1\n",
    "\n",
    "        weight2 = (np.random.rand(5, 1) * 2) - 1\n",
    "        bias2 = (np.random.randn(1,1)*2)-1\n",
    "\n",
    "        output = (np.random.rand(1, 1) * 2) - 1\n",
    "        outputBias = (np.random.rand(1, 1) * 2) - 1\n",
    "\n",
    "        tempWeight1 = weight1\n",
    "        tempBias1 = bias1\n",
    "\n",
    "        tempWeight2 = weight2\n",
    "        tempBias2 = bias2\n",
    "\n",
    "        tempOutput = weight3\n",
    "        tempOutputBias = bias3\n",
    "\n",
    "        return weight1, bias1, weight2, bias2, output, outputBias\n",
    "\n",
    "        \n",
    "    # BackPropogation Algorithm Begins:\n",
    "\n",
    "    # Forward Prop:\n",
    "    def forwardProp(weight1, bias1, weight2, bias2, output, outputBias, trainingData):\n",
    "        Z1 = weight1.dot(trainingData) + bias1\n",
    "        A1 = map(sigmoid, Z1)\n",
    "\n",
    "        Z2 = weight2.T.dot(A1) + bias2\n",
    "        A2 = map(sigmoid, Z2)\n",
    "\n",
    "        Z3 = output.T.dot(A2) + outputBias\n",
    "        A3 = map(sigmoid, Z3)\n",
    "\n",
    "        return Z1, A1, Z2, A2, Z3, A3\n",
    "    \n",
    "\n",
    "    # Back Prop:\n",
    "\n",
    "    def backProp(Z1, A1, Z2, A2, Z3, A3, answer, input):\n",
    "        third2 = deriv_lossFunction(answer, A3)\n",
    "        third1 = deriv_sigmoid(Z3)\n",
    "    \n",
    "        \n",
    "        temp3 = A2.dot(third2 * third1)\n",
    "\n",
    "        temp3Bias = third2 * third1\n",
    "\n",
    "        temp2 = A1.dot(((third2 * third1).dot(output)).dot(A2.dot((A2*-1) =+ 1)))\n",
    "    \n",
    "        temp2Bias = ((third2 * third1).dot(output)).dot(A2.dot((A2*-1) =+ 1))\n",
    "\n",
    "        temp1 = input.dot((weight2.dot(((third2 * third1).dot(output)).dot(A2.dot((A2*-1) += 1)))).dot(A1.dot((A1*-1) += 1)))\n",
    "    \n",
    "        temp1Bias = (weight2.dot(((third2 * third1).dot(output)).dot(A2.dot((A2*-1) += 1)))).dot(A1.dot((A1*-1) += 1))\n",
    "    \n",
    "\n",
    "        tempOutput = tempOutput - 0.01 * temp3\n",
    "    \n",
    "        tempOutputBias = tempOuputBias - 0.01 * temp3Bias\n",
    "    \n",
    "        tempWeight2 = tempWeight2 - 0.01 * temp2\n",
    "    \n",
    "        tempBias2 = tempBias2 - 0.01 * temp2Bias\n",
    "\n",
    "        tempWeight1 = tempWeight1 - 0.01 * temp1\n",
    "\n",
    "        tempBias1 = tempBias1 - 0.01 * temp1Bias\n",
    "\n",
    "        \n",
    "    def training(trainingData):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    weight1 = np.array()\n",
    "    bias1 = np.array()\n",
    "\n",
    "    weight2 = np.array()\n",
    "    bias2 = np.array()\n",
    "\n",
    "    output = np.array()\n",
    "    outputBias = np.array()\n",
    "\n",
    "    tempWeight1 = np.array()\n",
    "    tempBias1 = np.array()\n",
    "\n",
    "    tempWeight2 = np.array()\n",
    "    tempBias2 = np.array()\n",
    "\n",
    "    tempOutput = np.array()\n",
    "    tempOutputBias = np.array()\n",
    "\n",
    "\n",
    "\n",
    "# Processing and Normalizing Equations\n",
    "def normalize(dataArray):\n",
    "    '''\n",
    "    A normalization function that normalizes all of the data\n",
    "    in a 1D array between -1 and 1\n",
    "       \n",
    "    Args: \n",
    "    dataArray: A 1D numpy Array\n",
    "       \n",
    "    Returns: 1D array of Normalized Data'''\n",
    "    \n",
    "    maximum= np.amax(dataArray)\n",
    "    minimum = np.amin(dataArray)\n",
    "\n",
    "    returnArray = np.zeros(dataArray.size)\n",
    "\n",
    "    for i in range(dataArray.size):\n",
    "        returnArray[i] = 2*((dataArray[i] - minimum)/(maximum - minimum))-1\n",
    "\n",
    "    return returnArray\n",
    "\n",
    "#Loss Function: Binary Cross Entropy\n",
    "\n",
    "def lossFunction(corrVal, probability):\n",
    "    return -(corrVal*math.log(probability) + (1 - corrVal)*math.log(1-probability))\n",
    "\n",
    "# Derivative of the Loss Function:\n",
    "    \n",
    "def deriv_lossFunction(corrVal, probability):\n",
    "    return -corrVal/probability + (1-corrVal)/(1-probability)\n",
    "\n",
    "# Activation Function:\n",
    "\n",
    "def sigmoid(val):\n",
    "    '''My chosen activation function for this project'''\n",
    "    return 1/(1+math.exp(-val))\n",
    "\n",
    "#Derivative of the Activation Function:\n",
    "\n",
    "def deriv_sigmoid(val):\n",
    "    return sigmoid(val) * (1-sigmoid(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m m, n \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mshape\n\u001b[1;32m     16\u001b[0m data_set\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mT\n\u001b[0;32m---> 18\u001b[0m data_set[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m normalize(data_set[\u001b[39m0\u001b[39m])\n\u001b[1;32m     20\u001b[0m data_set[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(data_set[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mM\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m, data_set[\u001b[39m1\u001b[39m])\n\u001b[1;32m     21\u001b[0m data_set[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(data_set[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mF\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, data_set[\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normalize' is not defined"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "#Process and Standardize Raw Data\n",
    "\n",
    "dataSetUp=pd.read_csv(\"heart-data.csv\")\n",
    "\n",
    "data=np.array(dataSetUp)\n",
    "\n",
    "m, n = data.T.shape\n",
    "\n",
    "data_set=data.T\n",
    "\n",
    "data_set[0] = normalize(data_set[0])\n",
    "\n",
    "data_set[1] = np.where(data_set[1] == 'M', 1, data_set[1])\n",
    "data_set[1] = np.where(data_set[1] == 'F', -1, data_set[1])\n",
    "\n",
    "data_set[2] = np.where(data_set[2]==\"ATA\", 1, data_set[2])\n",
    "data_set[2] = np.where(data_set[2]==\"ASY\", -1, data_set[2])\n",
    "data_set[2] = np.where(data_set[2]==\"NAP\", 2, data_set[2])\n",
    "data_set[2] = np.where(data_set[2]==\"TA\", -2, data_set[2])\n",
    "\n",
    "data_set[2] = normalize(data_set[2])\n",
    "\n",
    "data_set[3] = normalize(data_set[3])\n",
    "\n",
    "data_set[4] = normalize(data_set[4])\n",
    "\n",
    "data_set[5] = normalize(data_set[5])\n",
    "\n",
    "data_set[6] = np.where(data_set[6] == 'Normal', -1, data_set[6])\n",
    "data_set[6] = np.where(data_set[6] == \"ST\", 0, data_set[6])\n",
    "data_set[6] = np.where(data_set[6] == \"LVH\", 1, data_set[6])\n",
    "\n",
    "data_set[6] = normalize(data_set[6])\n",
    "\n",
    "data_set[7] = normalize(data_set[7])\n",
    "\n",
    "data_set[8] = np.where(data_set[8] == 'Y', 1, data_set[8])\n",
    "data_set[8] = np.where(data_set[8] == 'N', -1, data_set[8])\n",
    "\n",
    "data_set[9] = normalize(data_set[9])\n",
    "\n",
    "data_set[10] = np.where(data_set[10] == \"Up\", 1, data_set[10])\n",
    "data_set[10] = np.where(data_set[10] == \"Flat\", 0, data_set[10])\n",
    "data_set[10] = np.where(data_set[10] == \"Down\", -1, data_set[10])\n",
    "\n",
    "val_set_answer = data_set[0:12, 0:100]\n",
    "\n",
    "val_set = data_set[0:11, 0:100]\n",
    "\n",
    "training_set = data_set[0:11, 100:917]\n",
    "\n",
    "\n",
    "print(training_set.shape)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
