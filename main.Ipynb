{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "# Algorithms:\n",
    "class Algorithms:\n",
    "\n",
    "    def _init_():\n",
    "        pass\n",
    "\n",
    "\n",
    "    #initializing weights and biases:\n",
    "    def init():\n",
    "        '''Initialize all weights and biases:\n",
    "        1 Hidden Layer\n",
    "        1 Output Layer'''\n",
    "        \n",
    "        weight1 = (np.random.rand(11, 5) * 2) - 1\n",
    "        bias1 = (np.random.randn(5,1)*2)-1\n",
    "\n",
    "        weight2 = (np.random.rand(5, 1) * 2) - 1\n",
    "        bias2 = (np.random.randn(1,1)*2)-1\n",
    "\n",
    "        output = (np.random.rand(1, 1) * 2) - 1\n",
    "        outputBias = (np.random.rand(1, 1) * 2) - 1\n",
    "\n",
    "        return weight1, bias1, weight2, bias2, output, outputBias\n",
    "\n",
    "        \n",
    "    # BackPropogation Algorithm Begins:\n",
    "\n",
    "    # Forward Prop:\n",
    "    def forwardProp(weight1, bias1, weight2, bias2, output, outputBias, trainingData):\n",
    "        weight1 = weight1.T\n",
    "        Z1 = weight1.dot(trainingData) + bias1\n",
    "        A1 = map(sigmoid, Z1)\n",
    "\n",
    "        weight2 = weight2.T\n",
    "        Z2 = weight2.T.dot(A1) + bias2\n",
    "        A2 = map(sigmoid, Z2)\n",
    "\n",
    "        Z3 = output.T.dot(A2) + outputBias\n",
    "        A3 = map(sigmoid, Z3)\n",
    "\n",
    "        return Z1, A1, Z2, A2, Z3, A3    \n",
    "\n",
    "    # Back Prop:\n",
    "\n",
    "    def backProp(): pass\n",
    "\n",
    "\n",
    "\n",
    "    weight1 = np.array()\n",
    "    bias1 = np.array()\n",
    "\n",
    "    weight2 = np.array()\n",
    "    bias2 = np.array()\n",
    "\n",
    "    output = np.array()\n",
    "    outputBias = np.array()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Processing and Normalizing Equations\n",
    "def normalize(dataArray):\n",
    "    '''\n",
    "    A normalization function that normalizes all of the data\n",
    "    in a 1D array between -1 and 1\n",
    "       \n",
    "    Args: \n",
    "    dataArray: A 1D numpy Array\n",
    "       \n",
    "    Returns: 1D array of Normalized Data'''\n",
    "    \n",
    "    maximum= np.amax(dataArray)\n",
    "    minimum = np.amin(dataArray)\n",
    "\n",
    "    returnArray = np.zeros(dataArray.size)\n",
    "\n",
    "    for i in range(dataArray.size):\n",
    "        returnArray[i] = 2*((dataArray[i] - minimum)/(maximum - minimum))-1\n",
    "\n",
    "    return returnArray\n",
    "\n",
    "# Activation Function:\n",
    "\n",
    "def sigmoid(val):\n",
    "    '''My chosen activation function for this project'''\n",
    "    return 1/(1+math.exp(-val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 100)\n"
     ]
    }
   ],
   "source": [
    "#Process and Standardize Raw Data\n",
    "\n",
    "dataSetUp=pd.read_csv(\"heart-data.csv\")\n",
    "\n",
    "data=np.array(dataSetUp)\n",
    "\n",
    "m, n = data.T.shape\n",
    "\n",
    "data_set=data.T\n",
    "\n",
    "data_set[0] = normalize(data_set[0])\n",
    "\n",
    "data_set[1] = np.where(data_set[1] == 'M', 1, data_set[1])\n",
    "data_set[1] = np.where(data_set[1] == 'F', -1, data_set[1])\n",
    "\n",
    "data_set[2] = np.where(data_set[2]==\"ATA\", 1, data_set[2])\n",
    "data_set[2] = np.where(data_set[2]==\"ASY\", -1, data_set[2])\n",
    "data_set[2] = np.where(data_set[2]==\"NAP\", 2, data_set[2])\n",
    "data_set[2] = np.where(data_set[2]==\"TA\", -2, data_set[2])\n",
    "\n",
    "data_set[2] = normalize(data_set[2])\n",
    "\n",
    "data_set[3] = normalize(data_set[3])\n",
    "\n",
    "data_set[4] = normalize(data_set[4])\n",
    "\n",
    "data_set[5] = normalize(data_set[5])\n",
    "\n",
    "data_set[6] = np.where(data_set[6] == 'Normal', -1, data_set[6])\n",
    "data_set[6] = np.where(data_set[6] == \"ST\", 0, data_set[6])\n",
    "data_set[6] = np.where(data_set[6] == \"LVH\", 1, data_set[6])\n",
    "\n",
    "data_set[6] = normalize(data_set[6])\n",
    "\n",
    "data_set[7] = normalize(data_set[7])\n",
    "\n",
    "data_set[8] = np.where(data_set[8] == 'Y', 1, data_set[8])\n",
    "data_set[8] = np.where(data_set[8] == 'N', -1, data_set[8])\n",
    "\n",
    "data_set[9] = normalize(data_set[9])\n",
    "\n",
    "data_set[10] = np.where(data_set[10] == \"Up\", 1, data_set[10])\n",
    "data_set[10] = np.where(data_set[10] == \"Flat\", 0, data_set[10])\n",
    "data_set[10] = np.where(data_set[10] == \"Down\", -1, data_set[10])\n",
    "\n",
    "val_set_answer = data_set[0:12, 0:100]\n",
    "\n",
    "val_set = data_set[0:11, 0:100]\n",
    "\n",
    "training_set = data_set[0:11, 100:917]\n",
    "\n",
    "\n",
    "print(val_set.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
